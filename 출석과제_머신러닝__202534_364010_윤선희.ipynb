{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYLdUP7bb0Ll2yXroLPcwm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyoonCS/DataAnalysis/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EA%B3%BC%EC%A0%9C(%EC%BD%94%EB%93%9C%2C_%EA%B3%BC%EC%A0%9C%EC%88%98%ED%96%89%EB%B3%B4%EA%B3%A0%EC%84%9C)_202534_364010(%EC%9C%A4%EC%84%A0%ED%9D%AC).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###머신러닝 출석과제 [K-근접이웃 분류기 구현하기]\n",
        "* 학  번 : 202534-364010\n",
        "* 성  명 : 윤선희\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lAoWDOBZCV8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<span style=\"color:blue\"> **1. 코드, 코드설명(주석)**</span>"
      ],
      "metadata": {
        "id": "x2BIpG_S-_ed"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BgEUah4G8L2s"
      },
      "outputs": [],
      "source": [
        "# 수행에 필요한 라이브러리 불러오기\n",
        "import csv           # csv 파일 읽기 위한 라이브러리\n",
        "import random        # 데이터 랜덤 처리 라이브러리 : 난수 생성, 리스트의 데이터를 랜덤으로 순서 변경 또는 데이터 추출\n",
        "import math          # 수학함수 제공\n",
        "import pandas as pd  # DataFrame, Series 데이터 객체 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) 데이터 불러오기"
      ],
      "metadata": {
        "id": "d7dDtfV_y0h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV 파일을 읽어서 리스트 형태로 저장, 데이터 구성 : # float형 특성값 4개, 정수형 레이블 1개(class)\n",
        "iris_data = []\n",
        "with open(\"iris_KNN.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    fdata = csv.reader(f)\n",
        "    for row in fdata:\n",
        "        features = list(map(float, row[:4]))  # map함수를 이용하여 list 4개 값을 float 변환하여 featuers list 구성\n",
        "        label = int(row[4])                   # class label\n",
        "        iris_data.append((features, label))   #리스트 형태로 iris_data 구성 ex: ([5.0, 3.5, 1.6, 0.6], 1)"
      ],
      "metadata": {
        "id": "ftGXPHqwuu8l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) 학습데이터, 테스트데이터 분할"
      ],
      "metadata": {
        "id": "cBi1WOq43bTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 데이터 분할 : 학습 데이터와 테스트 데이터 분할\n",
        "random.shuffle(iris_data)    # 리스트의 데이터를 랜덤으로 순서 변경\n",
        "train_data = iris_data[:100] # 0~99까지 100개의 데이터를 뽑아 학습데이터로 할당\n",
        "test_data = iris_data[100:]  # 100~ 나머지 데이터를 테스트데이터로 할당"
      ],
      "metadata": {
        "id": "DdLYGDWpvYqp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) 거리 계산 함수(유클리디안 거리)\n",
        "* **유클리디안 거리(Euclidean distance)** : 두 점 사이의 직선 거리를 계산하는 방식, 벡터간 유사도 계산에 활용\n"
      ],
      "metadata": {
        "id": "DFosXNkO3hUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 유클리디안 거리 계산 : 두 리스트의 각 요소를 튜플로 처리하여, 차이 제곱근 계산\n",
        "def euclidean_distance(train_feature, test_feature) :\n",
        "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(train_feature, test_feature)))"
      ],
      "metadata": {
        "id": "XpLkDzspwS9x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) K-최근접이웃 분류기 구현\n",
        "* **K-NN(K-Nearest Neighborhood)** : 새로운 데이터와 가장 가까운 K개의 이웃 데이터의 클래스를 모아,\n",
        "다수결로 해당 데이터의 클래스를 결정하는 분류알고리즘(classfication, 지도학습)\n",
        "* K값(하이퍼파라미터) 선택이 중요하며, 너무 작으면 노이즈에 민감, 너무 크면 구분력이 떨어질 수 있다.\n",
        "* scikit-learn 알고리즘 : KNeighborsClassifier"
      ],
      "metadata": {
        "id": "PxhwzZPmfgS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_predict(train, test_feature, k):\n",
        "    # Step1. 학습 데이터와 테스트 데이터 사이의 거리를 계산\n",
        "    distances = []\n",
        "    for features, label in train:\n",
        "        dist = euclidean_distance(features, test_feature)\n",
        "        distances.append((dist, label))  # 거리와 해당 레이블을 튜플로 저장\n",
        "\n",
        "    # step2. 거리를 기준으로 오름차순 정렬\n",
        "    distances.sort(key=lambda x: x[0])\n",
        "\n",
        "    # step3. 가장 가까운 k개의 데이터 선택\n",
        "    k_nearest = distances[:k]\n",
        "\n",
        "    # step4. k개의 데이터의 레이블 카운트\n",
        "    label_count = {}\n",
        "    for dist, label in k_nearest:\n",
        "        if label in label_count:\n",
        "            label_count[label] += 1  # 이미 있으면 1 증가\n",
        "        else:\n",
        "            label_count[label] = 1  # 없으면 1로 초기화\n",
        "\n",
        "    # step5. 클래스 레이블 결정(다수결)\n",
        "    predicted_label = max(label_count, key=label_count.get)  # value 기준 최대값\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "r-rmJg5_wixg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5) K값에 따른 분류정확도(accuracy) 계산"
      ],
      "metadata": {
        "id": "_6shPhb7kZOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for k in [5, 10, 20, 30]:       # K값 하이퍼파라미터 지정\n",
        "    correct = 0\n",
        "    for features, label in test_data:\n",
        "        pred = knn_predict(train_data, features, k)\n",
        "        if pred == label:       # test_data의 label과 일치한 경우 카운트\n",
        "            correct += 1\n",
        "    accuracy = correct / len(test_data) * 100 # 분류정확도(accuracy) % 계산\n",
        "    results.append((k, accuracy))             # K값별 분류율 리스트 추가\n"
      ],
      "metadata": {
        "id": "sh9IkcO7xIqK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<span style=\"color:blue\"> **2. 실험결과표**</span>"
      ],
      "metadata": {
        "id": "JSlaiAw9lUUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[ K값에 따른 분류 결과 ]\")\n",
        "df = pd.DataFrame(results, columns=[\"K값\", \"분류율(%)\"])\n",
        "from IPython.display import display, HTML # HTML 형식 출력\n",
        "display(HTML(df.to_html()))               # DataFrame 결과를 HTML 표로 표현"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "XQE4zy4zxNmV",
        "outputId": "7b1e5e17-5a86-491c-b54f-5da97fd34106"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[K값에 따른 분류 결과]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>K값</th>\n",
              "      <th>분류율(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>94.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>92.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>88.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<span style=\"color:blue\"> **3. 결과분석**</span>\n",
        "(1) 실험 결과\n",
        "* K값이 가장 작은 경우(K=5) 분류율이 가장 높고 K값이 큰 경우(K=20) 분류율이 가장 낮았다.\n",
        "* KNN 알고리즘 특성상 하이퍼파라미터 K 값에 따라 영향을 받는다.\n",
        "* K가 작으면 훈련 데이터에 민감하여 과적합 우려, 노이즈 영향이 크고,\n",
        "* K가 크면 노이즈에는 강하나 구분력 저하, 과소적합 우려가 있다.\n",
        "\n",
        "(2) KNN 성능 향상을 위한 고려 사항\n",
        "* **최적 K값 선정 방법** : <span style=\"color:blue\">교차검증(Cross Validation)</span> 을 수행하여 검증 정확도가 가장 높은 K를 선택한다.\n",
        "* **거리 알고리즘 선택** : 데이터 특성(연속형, 범주형, 이상치 유무)에 따라 선택한다.\n",
        "  + 연속형 : 유클리디안(euclidean), 맨해튼 거리(manhattan, 격자계산)\n",
        "  + 범주형 : 해밍 거리(hamming)\n",
        "  + 상관관계 고려 : 마할라노비스(mahalanobis, 데이터 분산 고려)"
      ],
      "metadata": {
        "id": "2TBoslm5Kh4j"
      }
    }
  ]
}